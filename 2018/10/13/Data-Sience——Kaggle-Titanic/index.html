<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="zh-CN">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.2" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="日记," />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.2" />






<meta name="description" content="今天讨论班轮到我讲课，前一天从晚上六点半一直准备到凌晨两点，把前一段时间学习的一篇Kaggle上的文章总结了一下，再加了点模型融合的内容。早上八点半起的床，早饭都没吃就去教室了，结果连一个认真听的人都没有，呵呵，气得我讲完直接就走了，真是不知道这种课到底有什么用。 话虽如此，还是把自己总结的内容保存到这里吧，毕竟也是自己爆肝来的心血啊。   点击下载 12345678910111213141516">
<meta name="keywords" content="日记">
<meta property="og:type" content="article">
<meta property="og:title" content="Data Sience——Kaggle.Titanic">
<meta property="og:url" content="http://yoursite.com/2018/10/13/Data-Sience——Kaggle-Titanic/index.html">
<meta property="og:site_name" content="SE">
<meta property="og:description" content="今天讨论班轮到我讲课，前一天从晚上六点半一直准备到凌晨两点，把前一段时间学习的一篇Kaggle上的文章总结了一下，再加了点模型融合的内容。早上八点半起的床，早饭都没吃就去教室了，结果连一个认真听的人都没有，呵呵，气得我讲完直接就走了，真是不知道这种课到底有什么用。 话虽如此，还是把自己总结的内容保存到这里吧，毕竟也是自己爆肝来的心血啊。   点击下载 12345678910111213141516">
<meta property="og:locale" content="zh-CN">
<meta property="og:updated_time" content="2018-10-13T04:37:37.887Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Data Sience——Kaggle.Titanic">
<meta name="twitter:description" content="今天讨论班轮到我讲课，前一天从晚上六点半一直准备到凌晨两点，把前一段时间学习的一篇Kaggle上的文章总结了一下，再加了点模型融合的内容。早上八点半起的床，早饭都没吃就去教室了，结果连一个认真听的人都没有，呵呵，气得我讲完直接就走了，真是不知道这种课到底有什么用。 话虽如此，还是把自己总结的内容保存到这里吧，毕竟也是自己爆肝来的心血啊。   点击下载 12345678910111213141516">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.2',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2018/10/13/Data-Sience——Kaggle-Titanic/"/>





  <title>Data Sience——Kaggle.Titanic | SE</title>
  




<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
            (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-108371787-1', 'auto');
  ga('send', 'pageview');
</script>





</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">SE</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">I Can Do All Things!</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/10/13/Data-Sience——Kaggle-Titanic/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="SE">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="SE">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Data Sience——Kaggle.Titanic</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-10-13T12:24:33+08:00">
                2018-10-13
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/10/13/Data-Sience——Kaggle-Titanic/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2018/10/13/Data-Sience——Kaggle-Titanic/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          
            <span class="post-meta-divider">|</span>
            <span class="page-pv"><i class="fa fa-file-o"></i>
            <span class="busuanzi-value" id="busuanzi_value_page_pv" ></span>
            </span>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>今天讨论班轮到我讲课，前一天从晚上六点半一直准备到凌晨两点，把前一段时间学习的一篇<a href="https://www.kaggle.com/startupsci/titanic-data-science-solutions" target="_blank" rel="external">Kaggle上的文章</a>总结了一下，再加了点模型融合的内容。早上八点半起的床，早饭都没吃就去教室了，结果连一个认真听的人都没有，呵呵，气得我讲完直接就走了，真是不知道这种课到底有什么用。</p>
<p>话虽如此，还是把自己总结的内容保存到这里吧，毕竟也是自己爆肝来的心血啊。</p>
<hr>
<p> <a href="/download/无标题.pptx&quot;">点击下载</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div><div class="line">162</div><div class="line">163</div><div class="line">164</div><div class="line">165</div><div class="line">166</div><div class="line">167</div><div class="line">168</div><div class="line">169</div><div class="line">170</div><div class="line">171</div><div class="line">172</div><div class="line">173</div><div class="line">174</div><div class="line">175</div><div class="line">176</div><div class="line">177</div><div class="line">178</div><div class="line">179</div><div class="line">180</div><div class="line">181</div><div class="line">182</div><div class="line">183</div><div class="line">184</div><div class="line">185</div><div class="line">186</div><div class="line">187</div><div class="line">188</div><div class="line">189</div><div class="line">190</div><div class="line">191</div><div class="line">192</div><div class="line">193</div><div class="line">194</div><div class="line">195</div><div class="line">196</div><div class="line">197</div><div class="line">198</div><div class="line">199</div><div class="line">200</div><div class="line">201</div><div class="line">202</div><div class="line">203</div><div class="line">204</div><div class="line">205</div><div class="line">206</div><div class="line">207</div><div class="line">208</div><div class="line">209</div><div class="line">210</div><div class="line">211</div><div class="line">212</div><div class="line">213</div><div class="line">214</div><div class="line">215</div><div class="line">216</div><div class="line">217</div><div class="line">218</div><div class="line">219</div><div class="line">220</div><div class="line">221</div><div class="line">222</div><div class="line">223</div><div class="line">224</div><div class="line">225</div><div class="line">226</div><div class="line">227</div><div class="line">228</div><div class="line">229</div><div class="line">230</div><div class="line">231</div><div class="line">232</div><div class="line">233</div><div class="line">234</div><div class="line">235</div><div class="line">236</div><div class="line">237</div><div class="line">238</div><div class="line">239</div><div class="line">240</div><div class="line">241</div><div class="line">242</div><div class="line">243</div><div class="line">244</div><div class="line">245</div><div class="line">246</div><div class="line">247</div><div class="line">248</div><div class="line">249</div><div class="line">250</div><div class="line">251</div><div class="line">252</div><div class="line">253</div><div class="line">254</div><div class="line">255</div><div class="line">256</div><div class="line">257</div><div class="line">258</div><div class="line">259</div><div class="line">260</div><div class="line">261</div><div class="line">262</div><div class="line">263</div><div class="line">264</div><div class="line">265</div><div class="line">266</div><div class="line">267</div><div class="line">268</div><div class="line">269</div><div class="line">270</div><div class="line">271</div><div class="line">272</div><div class="line">273</div><div class="line">274</div><div class="line">275</div><div class="line">276</div><div class="line">277</div><div class="line">278</div><div class="line">279</div><div class="line">280</div><div class="line">281</div><div class="line">282</div><div class="line">283</div><div class="line">284</div><div class="line">285</div><div class="line">286</div><div class="line">287</div><div class="line">288</div><div class="line">289</div><div class="line">290</div><div class="line">291</div><div class="line">292</div><div class="line">293</div><div class="line">294</div><div class="line">295</div><div class="line">296</div><div class="line">297</div><div class="line">298</div><div class="line">299</div><div class="line">300</div><div class="line">301</div><div class="line">302</div><div class="line">303</div><div class="line">304</div><div class="line">305</div><div class="line">306</div><div class="line">307</div><div class="line">308</div><div class="line">309</div><div class="line">310</div><div class="line">311</div><div class="line">312</div><div class="line">313</div><div class="line">314</div><div class="line">315</div><div class="line">316</div><div class="line">317</div><div class="line">318</div><div class="line">319</div><div class="line">320</div><div class="line">321</div><div class="line">322</div><div class="line">323</div><div class="line">324</div><div class="line">325</div><div class="line">326</div><div class="line">327</div><div class="line">328</div><div class="line">329</div><div class="line">330</div><div class="line">331</div><div class="line">332</div><div class="line">333</div><div class="line">334</div><div class="line">335</div><div class="line">336</div><div class="line">337</div><div class="line">338</div><div class="line">339</div><div class="line">340</div><div class="line">341</div><div class="line">342</div><div class="line">343</div><div class="line">344</div><div class="line">345</div><div class="line">346</div><div class="line">347</div><div class="line">348</div><div class="line">349</div><div class="line">350</div><div class="line">351</div><div class="line">352</div><div class="line">353</div><div class="line">354</div><div class="line">355</div><div class="line">356</div><div class="line">357</div><div class="line">358</div><div class="line">359</div><div class="line">360</div><div class="line">361</div><div class="line">362</div><div class="line">363</div><div class="line">364</div><div class="line">365</div><div class="line">366</div><div class="line">367</div><div class="line">368</div><div class="line">369</div><div class="line">370</div><div class="line">371</div><div class="line">372</div><div class="line">373</div><div class="line">374</div><div class="line">375</div><div class="line">376</div><div class="line">377</div><div class="line">378</div><div class="line">379</div><div class="line">380</div><div class="line">381</div><div class="line">382</div><div class="line">383</div><div class="line">384</div><div class="line">385</div><div class="line">386</div><div class="line">387</div><div class="line">388</div><div class="line">389</div><div class="line">390</div><div class="line">391</div><div class="line">392</div><div class="line">393</div><div class="line">394</div><div class="line">395</div><div class="line">396</div><div class="line">397</div><div class="line">398</div><div class="line">399</div><div class="line">400</div><div class="line">401</div><div class="line">402</div><div class="line">403</div><div class="line">404</div><div class="line">405</div><div class="line">406</div><div class="line">407</div><div class="line">408</div><div class="line">409</div><div class="line">410</div><div class="line">411</div><div class="line">412</div><div class="line">413</div><div class="line">414</div><div class="line">415</div><div class="line">416</div><div class="line">417</div><div class="line">418</div><div class="line">419</div><div class="line">420</div><div class="line">421</div><div class="line">422</div><div class="line">423</div><div class="line">424</div><div class="line">425</div><div class="line">426</div><div class="line">427</div><div class="line">428</div><div class="line">429</div><div class="line">430</div><div class="line">431</div><div class="line">432</div><div class="line">433</div><div class="line">434</div><div class="line">435</div><div class="line">436</div><div class="line">437</div><div class="line">438</div><div class="line">439</div><div class="line">440</div><div class="line">441</div><div class="line">442</div><div class="line">443</div><div class="line">444</div><div class="line">445</div><div class="line">446</div><div class="line">447</div><div class="line">448</div><div class="line">449</div><div class="line">450</div><div class="line">451</div><div class="line">452</div><div class="line">453</div><div class="line">454</div><div class="line">455</div><div class="line">456</div><div class="line">457</div><div class="line">458</div><div class="line">459</div><div class="line">460</div><div class="line">461</div><div class="line">462</div><div class="line">463</div><div class="line">464</div><div class="line">465</div><div class="line">466</div><div class="line">467</div><div class="line">468</div><div class="line">469</div><div class="line">470</div><div class="line">471</div><div class="line">472</div><div class="line">473</div><div class="line">474</div><div class="line">475</div><div class="line">476</div><div class="line">477</div><div class="line">478</div><div class="line">479</div><div class="line">480</div><div class="line">481</div><div class="line">482</div><div class="line">483</div><div class="line">484</div><div class="line">485</div><div class="line">486</div><div class="line">487</div><div class="line">488</div><div class="line">489</div><div class="line">490</div><div class="line">491</div><div class="line">492</div><div class="line">493</div><div class="line">494</div><div class="line">495</div><div class="line">496</div><div class="line">497</div><div class="line">498</div><div class="line">499</div><div class="line">500</div><div class="line">501</div><div class="line">502</div><div class="line">503</div><div class="line">504</div><div class="line">505</div><div class="line">506</div><div class="line">507</div><div class="line">508</div><div class="line">509</div><div class="line">510</div><div class="line">511</div><div class="line">512</div><div class="line">513</div><div class="line">514</div><div class="line">515</div><div class="line">516</div><div class="line">517</div><div class="line">518</div><div class="line">519</div><div class="line">520</div><div class="line">521</div><div class="line">522</div><div class="line">523</div><div class="line">524</div><div class="line">525</div><div class="line">526</div><div class="line">527</div><div class="line">528</div><div class="line">529</div><div class="line">530</div><div class="line">531</div><div class="line">532</div><div class="line">533</div><div class="line">534</div><div class="line">535</div><div class="line">536</div><div class="line">537</div><div class="line">538</div><div class="line">539</div><div class="line">540</div><div class="line">541</div><div class="line">542</div><div class="line">543</div><div class="line">544</div><div class="line">545</div><div class="line">546</div><div class="line">547</div><div class="line">548</div><div class="line">549</div><div class="line">550</div><div class="line">551</div><div class="line">552</div><div class="line">553</div><div class="line">554</div><div class="line">555</div><div class="line">556</div><div class="line">557</div><div class="line">558</div><div class="line">559</div><div class="line">560</div><div class="line">561</div><div class="line">562</div><div class="line">563</div><div class="line">564</div><div class="line">565</div><div class="line">566</div><div class="line">567</div><div class="line">568</div><div class="line">569</div><div class="line">570</div><div class="line">571</div><div class="line">572</div><div class="line">573</div><div class="line">574</div><div class="line">575</div><div class="line">576</div><div class="line">577</div><div class="line">578</div><div class="line">579</div><div class="line">580</div><div class="line">581</div><div class="line">582</div><div class="line">583</div><div class="line">584</div><div class="line">585</div><div class="line">586</div><div class="line">587</div><div class="line">588</div><div class="line">589</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># data analysis and wrangling</span></div><div class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">import</span> random <span class="keyword">as</span> rnd</div><div class="line"></div><div class="line"><span class="comment"># visualization</span></div><div class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"></div><div class="line"><span class="comment"># machine learning</span></div><div class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</div><div class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC, LinearSVC</div><div class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</div><div class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</div><div class="line"><span class="keyword">from</span> sklearn.naive_bayes <span class="keyword">import</span> GaussianNB</div><div class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> Perceptron</div><div class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> SGDClassifier</div><div class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</div><div class="line"></div><div class="line"><span class="keyword">import</span> re</div><div class="line"><span class="keyword">import</span> sklearn</div><div class="line"><span class="keyword">import</span> xgboost <span class="keyword">as</span> xgb</div><div class="line"><span class="keyword">import</span> plotly.offline <span class="keyword">as</span> py</div><div class="line"><span class="keyword">import</span> plotly.graph_objs <span class="keyword">as</span> go</div><div class="line"><span class="keyword">import</span> plotly.tools <span class="keyword">as</span> tls</div><div class="line"><span class="keyword">import</span> warnings</div><div class="line"></div><div class="line">warnings.filterwarnings(<span class="string">'ignore'</span>)</div><div class="line"><span class="comment"># Going to use these 5 base models for the stacking</span></div><div class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> (AdaBoostClassifier,</div><div class="line">                              GradientBoostingClassifier, ExtraTreesClassifier)</div><div class="line"><span class="keyword">from</span> sklearn.cross_validation <span class="keyword">import</span> KFold</div><div class="line"></div><div class="line">train_df = pd.read_csv(<span class="string">'C:/Users/dsz62/Desktop/Kaggle/Titanic/Models/input/train.csv'</span>)</div><div class="line">test_df = pd.read_csv(<span class="string">'C:/Users/dsz62/Desktop/Kaggle/Titanic/Models/input/test.csv'</span>)</div><div class="line">combine = [train_df, test_df]</div><div class="line"></div><div class="line"><span class="comment"># 1</span></div><div class="line">train_df.info()</div><div class="line">print(<span class="string">'_'</span> * <span class="number">40</span>)</div><div class="line">test_df.info()</div><div class="line"></div><div class="line">train_df.describe()</div><div class="line"></div><div class="line">train_df.describe(include=[<span class="string">'O'</span>])</div><div class="line"></div><div class="line"><span class="comment"># 2</span></div><div class="line"><span class="comment"># Sex</span></div><div class="line">train_df[[<span class="string">"Sex"</span>, <span class="string">"Survived"</span>]].groupby([<span class="string">'Sex'</span>], as_index=<span class="keyword">False</span>).mean().sort_values(by=<span class="string">'Survived'</span>, ascending=<span class="keyword">False</span>)</div><div class="line"><span class="comment"># Pclass</span></div><div class="line">train_df[[<span class="string">'Pclass'</span>, <span class="string">'Survived'</span>]].groupby([<span class="string">'Pclass'</span>], as_index=<span class="keyword">False</span>).mean().sort_values(by=<span class="string">'Survived'</span>, ascending=<span class="keyword">False</span>)</div><div class="line"><span class="comment"># Age</span></div><div class="line">g = sns.FacetGrid(train_df, col=<span class="string">'Survived'</span>)</div><div class="line">g.map(plt.hist, <span class="string">'Age'</span>, bins=<span class="number">20</span>)</div><div class="line">plt.show()</div><div class="line"><span class="comment"># SibSp</span></div><div class="line">train_df[[<span class="string">"SibSp"</span>, <span class="string">"Survived"</span>]].groupby([<span class="string">'SibSp'</span>], as_index=<span class="keyword">False</span>).mean().sort_values(by=<span class="string">'Survived'</span>, ascending=<span class="keyword">False</span>)</div><div class="line"><span class="comment"># Parch</span></div><div class="line">train_df[[<span class="string">"Parch"</span>, <span class="string">"Survived"</span>]].groupby([<span class="string">'Parch'</span>], as_index=<span class="keyword">False</span>).mean().sort_values(by=<span class="string">'Survived'</span>, ascending=<span class="keyword">False</span>)</div><div class="line"><span class="comment"># Age &amp; Pclass</span></div><div class="line">grid = sns.FacetGrid(train_df, col=<span class="string">'Survived'</span>, row=<span class="string">'Pclass'</span>, size=<span class="number">2.2</span>, aspect=<span class="number">1.6</span>)</div><div class="line">grid.map(plt.hist, <span class="string">'Age'</span>, alpha=<span class="number">.5</span>, bins=<span class="number">20</span>)</div><div class="line">grid.add_legend();</div><div class="line">plt.show()</div><div class="line"><span class="comment"># Pclass &amp; Sex &amp; Embarked</span></div><div class="line">grid = sns.FacetGrid(train_df, row=<span class="string">'Embarked'</span>, size=<span class="number">2.2</span>, aspect=<span class="number">1.6</span>)</div><div class="line">grid.map(sns.pointplot, <span class="string">'Pclass'</span>, <span class="string">'Survived'</span>, <span class="string">'Sex'</span>, palette=<span class="string">'deep'</span>)</div><div class="line">grid.add_legend()</div><div class="line">plt.show()</div><div class="line"><span class="comment"># Embarked &amp; Sex &amp; Fare</span></div><div class="line">grid = sns.FacetGrid(train_df, row=<span class="string">'Embarked'</span>, col=<span class="string">'Survived'</span>, size=<span class="number">2.2</span>, aspect=<span class="number">1.6</span>)</div><div class="line">grid.map(sns.barplot, <span class="string">'Sex'</span>, <span class="string">'Fare'</span>, alpha=<span class="number">.5</span>, ci=<span class="keyword">None</span>)</div><div class="line">grid.add_legend()</div><div class="line">plt.show()</div><div class="line"></div><div class="line"><span class="comment"># 3</span></div><div class="line"><span class="comment"># drop Ticket &amp; Cabin</span></div><div class="line">print(<span class="string">"Before"</span>, train_df.shape, test_df.shape, combine[<span class="number">0</span>].shape, combine[<span class="number">1</span>].shape)</div><div class="line"></div><div class="line">train_df = train_df.drop([<span class="string">'Ticket'</span>, <span class="string">'Cabin'</span>], axis=<span class="number">1</span>)</div><div class="line">test_df = test_df.drop([<span class="string">'Ticket'</span>, <span class="string">'Cabin'</span>], axis=<span class="number">1</span>)</div><div class="line">combine = [train_df, test_df]</div><div class="line"></div><div class="line"><span class="string">"After"</span>, train_df.shape, test_df.shape, combine[<span class="number">0</span>].shape, combine[<span class="number">1</span>].shape</div><div class="line"><span class="comment"># create Title, drop Name &amp; PassengerId</span></div><div class="line"><span class="keyword">for</span> dataset <span class="keyword">in</span> combine:</div><div class="line">    dataset[<span class="string">'Title'</span>] = dataset.Name.str.extract(<span class="string">' ([A-Za-z]+)\.'</span>, expand=<span class="keyword">False</span>)</div><div class="line"></div><div class="line">pd.crosstab(train_df[<span class="string">'Title'</span>], train_df[<span class="string">'Sex'</span>])</div><div class="line"></div><div class="line"><span class="keyword">for</span> dataset <span class="keyword">in</span> combine:</div><div class="line">    dataset[<span class="string">'Title'</span>] = dataset[<span class="string">'Title'</span>].replace([<span class="string">'Lady'</span>, <span class="string">'Countess'</span>, <span class="string">'Capt'</span>, <span class="string">'Col'</span>, \</div><div class="line">                                                 <span class="string">'Don'</span>, <span class="string">'Dr'</span>, <span class="string">'Major'</span>, <span class="string">'Rev'</span>, <span class="string">'Sir'</span>, <span class="string">'Jonkheer'</span>, <span class="string">'Dona'</span>], <span class="string">'Rare'</span>)</div><div class="line">    dataset[<span class="string">'Title'</span>] = dataset[<span class="string">'Title'</span>].replace(<span class="string">'Mlle'</span>, <span class="string">'Miss'</span>)</div><div class="line">    dataset[<span class="string">'Title'</span>] = dataset[<span class="string">'Title'</span>].replace(<span class="string">'Ms'</span>, <span class="string">'Miss'</span>)</div><div class="line">    dataset[<span class="string">'Title'</span>] = dataset[<span class="string">'Title'</span>].replace(<span class="string">'Mme'</span>, <span class="string">'Mrs'</span>)</div><div class="line"></div><div class="line">train_df[[<span class="string">'Title'</span>, <span class="string">'Survived'</span>]].groupby([<span class="string">'Title'</span>], as_index=<span class="keyword">False</span>).mean()</div><div class="line"></div><div class="line">title_mapping = &#123;<span class="string">"Mr"</span>: <span class="number">1</span>, <span class="string">"Miss"</span>: <span class="number">2</span>, <span class="string">"Mrs"</span>: <span class="number">3</span>, <span class="string">"Master"</span>: <span class="number">4</span>, <span class="string">"Rare"</span>: <span class="number">5</span>&#125;</div><div class="line"><span class="keyword">for</span> dataset <span class="keyword">in</span> combine:</div><div class="line">    dataset[<span class="string">'Title'</span>] = dataset[<span class="string">'Title'</span>].map(title_mapping)</div><div class="line">    dataset[<span class="string">'Title'</span>] = dataset[<span class="string">'Title'</span>].fillna(<span class="number">0</span>)</div><div class="line"></div><div class="line">train_df = train_df.drop([<span class="string">'Name'</span>, <span class="string">'PassengerId'</span>], axis=<span class="number">1</span>)</div><div class="line">test_df = test_df.drop([<span class="string">'Name'</span>], axis=<span class="number">1</span>)</div><div class="line">combine = [train_df, test_df]</div><div class="line">train_df.shape, test_df.shape</div><div class="line"><span class="comment"># Convert Sex</span></div><div class="line"><span class="keyword">for</span> dataset <span class="keyword">in</span> combine:</div><div class="line">    dataset[<span class="string">'Sex'</span>] = dataset[<span class="string">'Sex'</span>].map(&#123;<span class="string">'female'</span>: <span class="number">1</span>, <span class="string">'male'</span>: <span class="number">0</span>&#125;).astype(int)</div><div class="line"></div><div class="line"><span class="comment"># Convert Age</span></div><div class="line">grid = sns.FacetGrid(train_df, row=<span class="string">'Pclass'</span>, col=<span class="string">'Sex'</span>, size=<span class="number">2.2</span>, aspect=<span class="number">1.6</span>)</div><div class="line">grid.map(plt.hist, <span class="string">'Age'</span>, alpha=<span class="number">.5</span>, bins=<span class="number">20</span>)</div><div class="line">grid.add_legend()</div><div class="line">plt.show()</div><div class="line"></div><div class="line">guess_ages = np.zeros((<span class="number">2</span>, <span class="number">3</span>))</div><div class="line"><span class="keyword">for</span> dataset <span class="keyword">in</span> combine:</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, <span class="number">2</span>):</div><div class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">0</span>, <span class="number">3</span>):</div><div class="line">            guess_df = dataset[(dataset[<span class="string">'Sex'</span>] == i) &amp; \</div><div class="line">                               (dataset[<span class="string">'Pclass'</span>] == j + <span class="number">1</span>)][<span class="string">'Age'</span>].dropna()</div><div class="line">            age_guess = guess_df.median()</div><div class="line">            guess_ages[i, j] = int(age_guess / <span class="number">0.5</span> + <span class="number">0.5</span>) * <span class="number">0.5</span></div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, <span class="number">2</span>):</div><div class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">0</span>, <span class="number">3</span>):</div><div class="line">            dataset.loc[(dataset.Age.isnull()) &amp; (dataset.Sex == i) &amp; (dataset.Pclass == j + <span class="number">1</span>), \</div><div class="line">                        <span class="string">'Age'</span>] = guess_ages[i, j]</div><div class="line">    dataset[<span class="string">'Age'</span>] = dataset[<span class="string">'Age'</span>].astype(int)</div><div class="line"></div><div class="line">train_df[<span class="string">'AgeBand'</span>] = pd.cut(train_df[<span class="string">'Age'</span>], <span class="number">5</span>)</div><div class="line">train_df[[<span class="string">'AgeBand'</span>, <span class="string">'Survived'</span>]].groupby([<span class="string">'AgeBand'</span>], as_index=<span class="keyword">False</span>).mean().sort_values(by=<span class="string">'AgeBand'</span>, ascending=<span class="keyword">True</span>)</div><div class="line"></div><div class="line"><span class="keyword">for</span> dataset <span class="keyword">in</span> combine:</div><div class="line">    dataset.loc[dataset[<span class="string">'Age'</span>] &lt;= <span class="number">16</span>, <span class="string">'Age'</span>] = <span class="number">0</span></div><div class="line">    dataset.loc[(dataset[<span class="string">'Age'</span>] &gt; <span class="number">16</span>) &amp; (dataset[<span class="string">'Age'</span>] &lt;= <span class="number">32</span>), <span class="string">'Age'</span>] = <span class="number">1</span></div><div class="line">    dataset.loc[(dataset[<span class="string">'Age'</span>] &gt; <span class="number">32</span>) &amp; (dataset[<span class="string">'Age'</span>] &lt;= <span class="number">48</span>), <span class="string">'Age'</span>] = <span class="number">2</span></div><div class="line">    dataset.loc[(dataset[<span class="string">'Age'</span>] &gt; <span class="number">48</span>) &amp; (dataset[<span class="string">'Age'</span>] &lt;= <span class="number">64</span>), <span class="string">'Age'</span>] = <span class="number">3</span></div><div class="line">    dataset.loc[dataset[<span class="string">'Age'</span>] &gt; <span class="number">64</span>, <span class="string">'Age'</span>]</div><div class="line"></div><div class="line">train_df = train_df.drop([<span class="string">'AgeBand'</span>], axis=<span class="number">1</span>)</div><div class="line">combine = [train_df, test_df]</div><div class="line"></div><div class="line">train_df.head()</div><div class="line"><span class="comment"># Create FamilySize, drop SibSp &amp; Parch</span></div><div class="line"><span class="keyword">for</span> dataset <span class="keyword">in</span> combine:</div><div class="line">    dataset[<span class="string">'FamilySize'</span>] = dataset[<span class="string">'SibSp'</span>] + dataset[<span class="string">'Parch'</span>] + <span class="number">1</span></div><div class="line"></div><div class="line">train_df[[<span class="string">'FamilySize'</span>, <span class="string">'Survived'</span>]].groupby([<span class="string">'FamilySize'</span>], as_index=<span class="keyword">False</span>).mean().sort_values(by=<span class="string">'Survived'</span>,</div><div class="line">                                                                                                ascending=<span class="keyword">False</span>)</div><div class="line"><span class="comment"># Create IsAlone, drop FamilySize</span></div><div class="line"><span class="keyword">for</span> dataset <span class="keyword">in</span> combine:</div><div class="line">    dataset[<span class="string">'IsAlone'</span>] = <span class="number">0</span></div><div class="line">    dataset.loc[dataset[<span class="string">'FamilySize'</span>] == <span class="number">1</span>, <span class="string">'IsAlone'</span>] = <span class="number">1</span></div><div class="line"></div><div class="line">train_df = train_df.drop([<span class="string">'Parch'</span>, <span class="string">'SibSp'</span>, <span class="string">'FamilySize'</span>], axis=<span class="number">1</span>)</div><div class="line">test_df = test_df.drop([<span class="string">'Parch'</span>, <span class="string">'SibSp'</span>, <span class="string">'FamilySize'</span>], axis=<span class="number">1</span>)</div><div class="line">combine = [train_df, test_df]</div><div class="line">train_df[[<span class="string">'IsAlone'</span>, <span class="string">'Survived'</span>]].groupby([<span class="string">'IsAlone'</span>], as_index=<span class="keyword">False</span>).mean()</div><div class="line"></div><div class="line"><span class="comment"># Create Age*Pclass</span></div><div class="line"><span class="keyword">for</span> dataset <span class="keyword">in</span> combine:</div><div class="line">    dataset[<span class="string">'Age*Class'</span>] = dataset.Age * dataset.Pclass</div><div class="line"></div><div class="line">train_df.loc[:, [<span class="string">'Age*Class'</span>, <span class="string">'Age'</span>, <span class="string">'Pclass'</span>]].head(<span class="number">10</span>)</div><div class="line"></div><div class="line"><span class="comment"># Complete Embarked &amp; to num</span></div><div class="line">train_df.info()</div><div class="line"></div><div class="line">freq_port = train_df.Embarked.dropna().mode()[<span class="number">0</span>]</div><div class="line">freq_port</div><div class="line"></div><div class="line"><span class="keyword">for</span> dataset <span class="keyword">in</span> combine:</div><div class="line">    dataset[<span class="string">'Embarked'</span>] = dataset[<span class="string">'Embarked'</span>].fillna(freq_port)</div><div class="line"></div><div class="line">train_df[[<span class="string">'Embarked'</span>, <span class="string">'Survived'</span>]].groupby([<span class="string">'Embarked'</span>], as_index=<span class="keyword">False</span>).mean().sort_values(by=<span class="string">'Survived'</span>,</div><div class="line">                                                                                            ascending=<span class="keyword">False</span>)</div><div class="line"></div><div class="line"><span class="keyword">for</span> dataset <span class="keyword">in</span> combine:</div><div class="line">    dataset[<span class="string">'Embarked'</span>] = dataset[<span class="string">'Embarked'</span>].map(&#123;<span class="string">'S'</span>: <span class="number">0</span>, <span class="string">'C'</span>: <span class="number">1</span>, <span class="string">'Q'</span>: <span class="number">2</span>&#125;).astype(int)</div><div class="line"></div><div class="line">train_df.head()</div><div class="line"></div><div class="line"><span class="comment"># Complete Fare &amp; to discrete num</span></div><div class="line">test_df.info()</div><div class="line"></div><div class="line">test_df[<span class="string">'Fare'</span>].fillna(test_df[<span class="string">'Fare'</span>].dropna().median(), inplace=<span class="keyword">True</span>)</div><div class="line">train_df[<span class="string">'FareBand'</span>] = pd.qcut(train_df[<span class="string">'Fare'</span>], <span class="number">4</span>)</div><div class="line">train_df[[<span class="string">'FareBand'</span>, <span class="string">'Survived'</span>]].groupby([<span class="string">'FareBand'</span>], as_index=<span class="keyword">False</span>).mean().sort_values(by=<span class="string">'FareBand'</span>,</div><div class="line">                                                                                            ascending=<span class="keyword">True</span>)</div><div class="line"></div><div class="line"><span class="keyword">for</span> dataset <span class="keyword">in</span> combine:</div><div class="line">    dataset.loc[dataset[<span class="string">'Fare'</span>] &lt;= <span class="number">7.91</span>, <span class="string">'Fare'</span>] = <span class="number">0</span></div><div class="line">    dataset.loc[(dataset[<span class="string">'Fare'</span>] &gt; <span class="number">7.91</span>) &amp; (dataset[<span class="string">'Fare'</span>] &lt;= <span class="number">14.454</span>), <span class="string">'Fare'</span>] = <span class="number">1</span></div><div class="line">    dataset.loc[(dataset[<span class="string">'Fare'</span>] &gt; <span class="number">14.454</span>) &amp; (dataset[<span class="string">'Fare'</span>] &lt;= <span class="number">31</span>), <span class="string">'Fare'</span>] = <span class="number">2</span></div><div class="line">    dataset.loc[dataset[<span class="string">'Fare'</span>] &gt; <span class="number">31</span>, <span class="string">'Fare'</span>] = <span class="number">3</span></div><div class="line">    dataset[<span class="string">'Fare'</span>] = dataset[<span class="string">'Fare'</span>].astype(int)</div><div class="line"></div><div class="line">train_df = train_df.drop([<span class="string">'FareBand'</span>], axis=<span class="number">1</span>)</div><div class="line">combine = [train_df, test_df]</div><div class="line"></div><div class="line">train_df.head(<span class="number">10</span>)</div><div class="line"></div><div class="line">test_df.head(<span class="number">10</span>)</div><div class="line"></div><div class="line"><span class="comment"># Model, predict and solve</span></div><div class="line">X_train = train_df.drop(<span class="string">"Survived"</span>, axis=<span class="number">1</span>)</div><div class="line">Y_train = train_df[<span class="string">"Survived"</span>]</div><div class="line">X_test = test_df.drop(<span class="string">"PassengerId"</span>, axis=<span class="number">1</span>).copy()</div><div class="line">X_train.shape, Y_train.shape, X_test.shape</div><div class="line"></div><div class="line"><span class="comment"># Logistic Regression</span></div><div class="line">logreg = LogisticRegression()</div><div class="line">logreg.fit(X_train, Y_train)</div><div class="line">Y_pred = logreg.predict(X_test)</div><div class="line">acc_log = round(logreg.score(X_train, Y_train) * <span class="number">100</span>, <span class="number">2</span>)</div><div class="line">acc_log</div><div class="line"></div><div class="line">coeff_df = pd.DataFrame(train_df.columns.delete(<span class="number">0</span>))</div><div class="line">coeff_df.columns = [<span class="string">'Feature'</span>]</div><div class="line">coeff_df[<span class="string">"Correlation"</span>] = pd.Series(logreg.coef_[<span class="number">0</span>])</div><div class="line">coeff_df.sort_values(by=<span class="string">'Correlation'</span>, ascending=<span class="keyword">False</span>)</div><div class="line"></div><div class="line"><span class="comment"># Support Vector Machines</span></div><div class="line">svc = SVC()</div><div class="line">svc.fit(X_train, Y_train)</div><div class="line">Y_pred = svc.predict(X_test)</div><div class="line">acc_svc = round(svc.score(X_train, Y_train) * <span class="number">100</span>, <span class="number">2</span>)</div><div class="line">acc_svc</div><div class="line"></div><div class="line"><span class="comment"># KNN</span></div><div class="line">knn = KNeighborsClassifier(n_neighbors=<span class="number">3</span>)</div><div class="line">knn.fit(X_train, Y_train)</div><div class="line">Y_pred = knn.predict(X_test)</div><div class="line">acc_knn = round(knn.score(X_train, Y_train) * <span class="number">100</span>, <span class="number">2</span>)</div><div class="line">acc_knn</div><div class="line"></div><div class="line"><span class="comment"># Gaussian Naive Bayes</span></div><div class="line">gaussian = GaussianNB()</div><div class="line">gaussian.fit(X_train, Y_train)</div><div class="line">Y_pred = gaussian.predict(X_test)</div><div class="line">acc_gaussian = round(gaussian.score(X_train, Y_train) * <span class="number">100</span>, <span class="number">2</span>)</div><div class="line">acc_gaussian</div><div class="line"></div><div class="line"><span class="comment"># Perceptron</span></div><div class="line">perceptron = Perceptron()</div><div class="line">perceptron.fit(X_train, Y_train)</div><div class="line">Y_pred = perceptron.predict(X_test)</div><div class="line">acc_perceptron = round(perceptron.score(X_train, Y_train) * <span class="number">100</span>, <span class="number">2</span>)</div><div class="line">acc_perceptron</div><div class="line"></div><div class="line"><span class="comment"># Linear SVC</span></div><div class="line">linear_svc = LinearSVC()</div><div class="line">linear_svc.fit(X_train, Y_train)</div><div class="line">Y_pred = linear_svc.predict(X_test)</div><div class="line">acc_linear_svc = round(linear_svc.score(X_train, Y_train) * <span class="number">100</span>, <span class="number">2</span>)</div><div class="line">acc_linear_svc</div><div class="line"></div><div class="line"><span class="comment"># Stochastic Gradient Descent</span></div><div class="line">sgd = SGDClassifier()</div><div class="line">sgd.fit(X_train, Y_train)</div><div class="line">Y_pred = sgd.predict(X_test)</div><div class="line">acc_sgd = round(sgd.score(X_train, Y_train) * <span class="number">100</span>, <span class="number">2</span>)</div><div class="line">acc_sgd</div><div class="line"></div><div class="line"><span class="comment"># Decision Tree</span></div><div class="line">decision_tree = DecisionTreeClassifier()</div><div class="line">decision_tree.fit(X_train, Y_train)</div><div class="line">Y_pred = decision_tree.predict(X_test)</div><div class="line">acc_decision_tree = round(decision_tree.score(X_train, Y_train) * <span class="number">100</span>, <span class="number">2</span>)</div><div class="line">acc_decision_tree</div><div class="line"></div><div class="line"><span class="comment"># Random Forest</span></div><div class="line">random_forest = RandomForestClassifier(n_estimators=<span class="number">100</span>)</div><div class="line">random_forest.fit(X_train, Y_train)</div><div class="line">Y_pred = random_forest.predict(X_test)</div><div class="line">random_forest.score(X_train, Y_train)</div><div class="line">acc_random_forest = round(random_forest.score(X_train, Y_train) * <span class="number">100</span>, <span class="number">2</span>)</div><div class="line">acc_random_forest</div><div class="line"></div><div class="line"><span class="comment"># Model evaluation</span></div><div class="line">models = pd.DataFrame(&#123;</div><div class="line">    <span class="string">'Model'</span>: [<span class="string">'Support Vector Machines'</span>, <span class="string">'KNN'</span>, <span class="string">'Logistic Regression'</span>,</div><div class="line">              <span class="string">'Random Forest'</span>, <span class="string">'Naive Bayes'</span>, <span class="string">'Perceptron'</span>,</div><div class="line">              <span class="string">'Stochastic Gradient Decent'</span>, <span class="string">'Linear SVC'</span>,</div><div class="line">              <span class="string">'Decision Tree'</span>],</div><div class="line">    <span class="string">'Score'</span>: [acc_svc, acc_knn, acc_log,</div><div class="line">              acc_random_forest, acc_gaussian, acc_perceptron,</div><div class="line">              acc_sgd, acc_linear_svc, acc_decision_tree]&#125;)</div><div class="line">models.sort_values(by=<span class="string">'Score'</span>, ascending=<span class="keyword">False</span>)</div><div class="line"></div><div class="line"><span class="comment">#########################################################################</span></div><div class="line"></div><div class="line">colormap = plt.cm.RdBu</div><div class="line">plt.figure(figsize=(<span class="number">14</span>, <span class="number">12</span>))</div><div class="line">plt.title(<span class="string">'Pearson Correlation of Features'</span>, y=<span class="number">1.05</span>, size=<span class="number">15</span>)</div><div class="line">sns.heatmap(train_df.astype(float).corr(), linewidths=<span class="number">0.1</span>, vmax=<span class="number">1.0</span>,</div><div class="line">            square=<span class="keyword">True</span>, cmap=colormap, linecolor=<span class="string">'white'</span>, annot=<span class="keyword">True</span>)</div><div class="line">plt.show()</div><div class="line"></div><div class="line"><span class="comment">#########################################################################</span></div><div class="line"></div><div class="line"><span class="comment"># Some useful parameters which will come in handy later on</span></div><div class="line">ntrain = train_df.shape[<span class="number">0</span>]</div><div class="line">ntest = test_df.shape[<span class="number">0</span>]</div><div class="line">SEED = <span class="number">0</span>  <span class="comment"># for reproducibility</span></div><div class="line">NFOLDS = <span class="number">5</span>  <span class="comment"># set folds for out-of-fold prediction</span></div><div class="line">kf = KFold(ntrain, n_folds=NFOLDS, random_state=SEED)</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># Class to extend the Sklearn classifier</span></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">SklearnHelper</span><span class="params">(object)</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, clf, seed=<span class="number">0</span>, params=None)</span>:</span></div><div class="line">        params[<span class="string">'random_state'</span>] = seed</div><div class="line">        self.clf = clf(**params)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">train_df</span><span class="params">(self, x_train, y_train)</span>:</span></div><div class="line">        self.clf.fit(x_train, y_train)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(self, x)</span>:</span></div><div class="line">        <span class="keyword">return</span> self.clf.predict(x)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span><span class="params">(self, x, y)</span>:</span></div><div class="line">        <span class="keyword">return</span> self.clf.fit(x, y)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">feature_importances</span><span class="params">(self, x, y)</span>:</span></div><div class="line">        print(self.clf.fit(x, y).feature_importances_)</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># Class to extend XGboost classifer</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_oof</span><span class="params">(clf, x_train, y_train, x_test)</span>:</span></div><div class="line">    oof_train = np.zeros((ntrain,))</div><div class="line">    oof_test = np.zeros((ntest,))</div><div class="line">    oof_test_skf = np.empty((NFOLDS, ntest))</div><div class="line"></div><div class="line">    <span class="keyword">for</span> i, (train_index, test_index) <span class="keyword">in</span> enumerate(kf):</div><div class="line">        x_tr = x_train[train_index]</div><div class="line">        y_tr = y_train[train_index]</div><div class="line">        x_te = x_train[test_index]</div><div class="line"></div><div class="line">        clf.train_df(x_tr, y_tr)</div><div class="line"></div><div class="line">        oof_train[test_index] = clf.predict(x_te)</div><div class="line">        oof_test_skf[i, :] = clf.predict(x_test)</div><div class="line"></div><div class="line">    oof_test[:] = oof_test_skf.mean(axis=<span class="number">0</span>)</div><div class="line">    <span class="keyword">return</span> oof_train.reshape(<span class="number">-1</span>, <span class="number">1</span>), oof_test.reshape(<span class="number">-1</span>, <span class="number">1</span>)</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># Put in our parameters for said classifiers</span></div><div class="line"><span class="comment"># Random Forest parameters</span></div><div class="line">rf_params = &#123;</div><div class="line">    <span class="string">'n_jobs'</span>: <span class="number">-1</span>,</div><div class="line">    <span class="string">'n_estimators'</span>: <span class="number">500</span>,</div><div class="line">    <span class="string">'warm_start'</span>: <span class="keyword">True</span>,</div><div class="line">    <span class="comment"># 'max_features': 0.2,</span></div><div class="line">    <span class="string">'max_depth'</span>: <span class="number">6</span>,</div><div class="line">    <span class="string">'min_samples_leaf'</span>: <span class="number">2</span>,</div><div class="line">    <span class="string">'max_features'</span>: <span class="string">'sqrt'</span>,</div><div class="line">    <span class="string">'verbose'</span>: <span class="number">0</span></div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment"># Extra Trees Parameters</span></div><div class="line">et_params = &#123;</div><div class="line">    <span class="string">'n_jobs'</span>: <span class="number">-1</span>,</div><div class="line">    <span class="string">'n_estimators'</span>: <span class="number">500</span>,</div><div class="line">    <span class="comment"># 'max_features': 0.5,</span></div><div class="line">    <span class="string">'max_depth'</span>: <span class="number">8</span>,</div><div class="line">    <span class="string">'min_samples_leaf'</span>: <span class="number">2</span>,</div><div class="line">    <span class="string">'verbose'</span>: <span class="number">0</span></div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment"># AdaBoost parameters</span></div><div class="line">ada_params = &#123;</div><div class="line">    <span class="string">'n_estimators'</span>: <span class="number">500</span>,</div><div class="line">    <span class="string">'learning_rate'</span>: <span class="number">0.75</span></div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment"># Gradient Boosting parameters</span></div><div class="line">gb_params = &#123;</div><div class="line">    <span class="string">'n_estimators'</span>: <span class="number">500</span>,</div><div class="line">    <span class="comment"># 'max_features': 0.2,</span></div><div class="line">    <span class="string">'max_depth'</span>: <span class="number">5</span>,</div><div class="line">    <span class="string">'min_samples_leaf'</span>: <span class="number">2</span>,</div><div class="line">    <span class="string">'verbose'</span>: <span class="number">0</span></div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment"># Support Vector Classifier parameters </span></div><div class="line">svc_params = &#123;</div><div class="line">    <span class="string">'kernel'</span>: <span class="string">'linear'</span>,</div><div class="line">    <span class="string">'C'</span>: <span class="number">0.025</span></div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment"># Create 5 objects that represent our 4 models</span></div><div class="line">rf = SklearnHelper(clf=RandomForestClassifier, seed=SEED, params=rf_params)</div><div class="line">et = SklearnHelper(clf=ExtraTreesClassifier, seed=SEED, params=et_params)</div><div class="line">ada = SklearnHelper(clf=AdaBoostClassifier, seed=SEED, params=ada_params)</div><div class="line">gb = SklearnHelper(clf=GradientBoostingClassifier, seed=SEED, params=gb_params)</div><div class="line">svc = SklearnHelper(clf=SVC, seed=SEED, params=svc_params)</div><div class="line"><span class="comment"># Create Numpy arrays of train_df, test_df and target ( Survived) dataframes to feed into our models</span></div><div class="line">y_train = train_df[<span class="string">'Survived'</span>].ravel()</div><div class="line">train_df = train_df.drop([<span class="string">'Survived'</span>], axis=<span class="number">1</span>)</div><div class="line">x_train = train_df.values  <span class="comment"># Creates an array of the train_df data</span></div><div class="line">x_test = test_df.values  <span class="comment"># Creats an array of the test_df data</span></div><div class="line"><span class="comment"># Create our OOF train_df and test_df predictions. These base results will be used as new features</span></div><div class="line">et_oof_train, et_oof_test = get_oof(et, x_train, y_train, x_test)  <span class="comment"># Extra Trees</span></div><div class="line">rf_oof_train, rf_oof_test = get_oof(rf, x_train, y_train, x_test)  <span class="comment"># Random Forest</span></div><div class="line">ada_oof_train, ada_oof_test = get_oof(ada, x_train, y_train, x_test)  <span class="comment"># AdaBoost</span></div><div class="line">gb_oof_train, gb_oof_test = get_oof(gb, x_train, y_train, x_test)  <span class="comment"># Gradient Boost</span></div><div class="line">svc_oof_train, svc_oof_test = get_oof(svc, x_train, y_train, x_test)  <span class="comment"># Support Vector Classifier</span></div><div class="line"></div><div class="line">print(<span class="string">"Training is complete"</span>)</div><div class="line">rf_feature = rf.feature_importances(x_train, y_train)</div><div class="line">et_feature = et.feature_importances(x_train, y_train)</div><div class="line">ada_feature = ada.feature_importances(x_train, y_train)</div><div class="line">gb_feature = gb.feature_importances(x_train, y_train)</div><div class="line">rf_features = [<span class="number">0.10474135</span>, <span class="number">0.21837029</span>, <span class="number">0.04432652</span>, <span class="number">0.02249159</span>, <span class="number">0.05432591</span>, <span class="number">0.02854371</span></div><div class="line">    , <span class="number">0.07570305</span>, <span class="number">0.01088129</span>, <span class="number">0.24247496</span>, <span class="number">0.13685733</span>, <span class="number">0.06128402</span>]</div><div class="line">et_features = [<span class="number">0.12165657</span>, <span class="number">0.37098307</span>, <span class="number">0.03129623</span>, <span class="number">0.01591611</span>, <span class="number">0.05525811</span>, <span class="number">0.028157</span></div><div class="line">    , <span class="number">0.04589793</span>, <span class="number">0.02030357</span>, <span class="number">0.17289562</span>, <span class="number">0.04853517</span>, <span class="number">0.08910063</span>]</div><div class="line">ada_features = [<span class="number">0.028</span>, <span class="number">0.008</span>, <span class="number">0.012</span>, <span class="number">0.05866667</span>, <span class="number">0.032</span>, <span class="number">0.008</span></div><div class="line">    , <span class="number">0.04666667</span>, <span class="number">0.</span>, <span class="number">0.05733333</span>, <span class="number">0.73866667</span>, <span class="number">0.01066667</span>]</div><div class="line">gb_features = [<span class="number">0.06796144</span>, <span class="number">0.03889349</span>, <span class="number">0.07237845</span>, <span class="number">0.02628645</span>, <span class="number">0.11194395</span>, <span class="number">0.04778854</span></div><div class="line">    , <span class="number">0.05965792</span>, <span class="number">0.02774745</span>, <span class="number">0.07462718</span>, <span class="number">0.4593142</span>, <span class="number">0.01340093</span>]</div><div class="line">cols = train_df.columns.values  <span class="comment"># Create a dataframe with features</span></div><div class="line">feature_dataframe = pd.DataFrame(&#123;<span class="string">'features'</span>: cols,</div><div class="line">                                  <span class="string">'Random Forest feature importances'</span>: rf_features,</div><div class="line">                                  <span class="string">'Extra Trees  feature importances'</span>: et_features,</div><div class="line">                                  <span class="string">'AdaBoost feature importances'</span>: ada_features,</div><div class="line">                                  <span class="string">'Gradient Boost feature importances'</span>: gb_features</div><div class="line">                                  &#125;)</div><div class="line"><span class="comment"># Scatter plot </span></div><div class="line">trace = go.Scatter(</div><div class="line">    y=feature_dataframe[<span class="string">'Random Forest feature importances'</span>].values,</div><div class="line">    x=feature_dataframe[<span class="string">'features'</span>].values,</div><div class="line">    mode=<span class="string">'markers'</span>,</div><div class="line">    marker=dict(</div><div class="line">        sizemode=<span class="string">'diameter'</span>,</div><div class="line">        sizeref=<span class="number">1</span>,</div><div class="line">        size=<span class="number">25</span>,</div><div class="line">        <span class="comment">#       size= feature_dataframe['AdaBoost feature importances'].values,</span></div><div class="line">        <span class="comment"># color = np.random.randn(500), #set color equal to a variable</span></div><div class="line">        color=feature_dataframe[<span class="string">'Random Forest feature importances'</span>].values,</div><div class="line">        colorscale=<span class="string">'Portland'</span>,</div><div class="line">        showscale=<span class="keyword">True</span></div><div class="line">    ),</div><div class="line">    text=feature_dataframe[<span class="string">'features'</span>].values</div><div class="line">)</div><div class="line">data = [trace]</div><div class="line"></div><div class="line">layout = go.Layout(</div><div class="line">    autosize=<span class="keyword">True</span>,</div><div class="line">    title=<span class="string">'Random Forest Feature Importance'</span>,</div><div class="line">    hovermode=<span class="string">'closest'</span>,</div><div class="line">    <span class="comment">#     xaxis= dict(</span></div><div class="line">    <span class="comment">#         title= 'Pop',</span></div><div class="line">    <span class="comment">#         ticklen= 5,</span></div><div class="line">    <span class="comment">#         zeroline= False,</span></div><div class="line">    <span class="comment">#         gridwidth= 2,</span></div><div class="line">    <span class="comment">#     ),</span></div><div class="line">    yaxis=dict(</div><div class="line">        title=<span class="string">'Feature Importance'</span>,</div><div class="line">        ticklen=<span class="number">5</span>,</div><div class="line">        gridwidth=<span class="number">2</span></div><div class="line">    ),</div><div class="line">    showlegend=<span class="keyword">False</span></div><div class="line">)</div><div class="line">fig = go.Figure(data=data, layout=layout)</div><div class="line">py.iplot(fig, filename=<span class="string">'scatter2010'</span>)</div><div class="line"></div><div class="line"><span class="comment"># Scatter plot </span></div><div class="line">trace = go.Scatter(</div><div class="line">    y=feature_dataframe[<span class="string">'Extra Trees  feature importances'</span>].values,</div><div class="line">    x=feature_dataframe[<span class="string">'features'</span>].values,</div><div class="line">    mode=<span class="string">'markers'</span>,</div><div class="line">    marker=dict(</div><div class="line">        sizemode=<span class="string">'diameter'</span>,</div><div class="line">        sizeref=<span class="number">1</span>,</div><div class="line">        size=<span class="number">25</span>,</div><div class="line">        <span class="comment">#       size= feature_dataframe['AdaBoost feature importances'].values,</span></div><div class="line">        <span class="comment"># color = np.random.randn(500), #set color equal to a variable</span></div><div class="line">        color=feature_dataframe[<span class="string">'Extra Trees  feature importances'</span>].values,</div><div class="line">        colorscale=<span class="string">'Portland'</span>,</div><div class="line">        showscale=<span class="keyword">True</span></div><div class="line">    ),</div><div class="line">    text=feature_dataframe[<span class="string">'features'</span>].values</div><div class="line">)</div><div class="line">data = [trace]</div><div class="line"></div><div class="line">layout = go.Layout(</div><div class="line">    autosize=<span class="keyword">True</span>,</div><div class="line">    title=<span class="string">'Extra Trees Feature Importance'</span>,</div><div class="line">    hovermode=<span class="string">'closest'</span>,</div><div class="line">    <span class="comment">#     xaxis= dict(</span></div><div class="line">    <span class="comment">#         title= 'Pop',</span></div><div class="line">    <span class="comment">#         ticklen= 5,</span></div><div class="line">    <span class="comment">#         zeroline= False,</span></div><div class="line">    <span class="comment">#         gridwidth= 2,</span></div><div class="line">    <span class="comment">#     ),</span></div><div class="line">    yaxis=dict(</div><div class="line">        title=<span class="string">'Feature Importance'</span>,</div><div class="line">        ticklen=<span class="number">5</span>,</div><div class="line">        gridwidth=<span class="number">2</span></div><div class="line">    ),</div><div class="line">    showlegend=<span class="keyword">False</span></div><div class="line">)</div><div class="line">fig = go.Figure(data=data, layout=layout)</div><div class="line">py.iplot(fig, filename=<span class="string">'scatter2010'</span>)</div><div class="line"></div><div class="line"><span class="comment"># Scatter plot </span></div><div class="line">trace = go.Scatter(</div><div class="line">    y=feature_dataframe[<span class="string">'AdaBoost feature importances'</span>].values,</div><div class="line">    x=feature_dataframe[<span class="string">'features'</span>].values,</div><div class="line">    mode=<span class="string">'markers'</span>,</div><div class="line">    marker=dict(</div><div class="line">        sizemode=<span class="string">'diameter'</span>,</div><div class="line">        sizeref=<span class="number">1</span>,</div><div class="line">        size=<span class="number">25</span>,</div><div class="line">        <span class="comment">#       size= feature_dataframe['AdaBoost feature importances'].values,</span></div><div class="line">        <span class="comment"># color = np.random.randn(500), #set color equal to a variable</span></div><div class="line">        color=feature_dataframe[<span class="string">'AdaBoost feature importances'</span>].values,</div><div class="line">        colorscale=<span class="string">'Portland'</span>,</div><div class="line">        showscale=<span class="keyword">True</span></div><div class="line">    ),</div><div class="line">    text=feature_dataframe[<span class="string">'features'</span>].values</div><div class="line">)</div><div class="line">data = [trace]</div><div class="line"></div><div class="line">layout = go.Layout(</div><div class="line">    autosize=<span class="keyword">True</span>,</div><div class="line">    title=<span class="string">'AdaBoost Feature Importance'</span>,</div><div class="line">    hovermode=<span class="string">'closest'</span>,</div><div class="line">    <span class="comment">#     xaxis= dict(</span></div><div class="line">    <span class="comment">#         title= 'Pop',</span></div><div class="line">    <span class="comment">#         ticklen= 5,</span></div><div class="line">    <span class="comment">#         zeroline= False,</span></div><div class="line">    <span class="comment">#         gridwidth= 2,</span></div><div class="line">    <span class="comment">#     ),</span></div><div class="line">    yaxis=dict(</div><div class="line">        title=<span class="string">'Feature Importance'</span>,</div><div class="line">        ticklen=<span class="number">5</span>,</div><div class="line">        gridwidth=<span class="number">2</span></div><div class="line">    ),</div><div class="line">    showlegend=<span class="keyword">False</span></div><div class="line">)</div><div class="line">fig = go.Figure(data=data, layout=layout)</div><div class="line">py.iplot(fig, filename=<span class="string">'scatter2010'</span>)</div><div class="line"></div><div class="line"><span class="comment"># Scatter plot </span></div><div class="line">trace = go.Scatter(</div><div class="line">    y=feature_dataframe[<span class="string">'Gradient Boost feature importances'</span>].values,</div><div class="line">    x=feature_dataframe[<span class="string">'features'</span>].values,</div><div class="line">    mode=<span class="string">'markers'</span>,</div><div class="line">    marker=dict(</div><div class="line">        sizemode=<span class="string">'diameter'</span>,</div><div class="line">        sizeref=<span class="number">1</span>,</div><div class="line">        size=<span class="number">25</span>,</div><div class="line">        <span class="comment">#       size= feature_dataframe['AdaBoost feature importances'].values,</span></div><div class="line">        <span class="comment"># color = np.random.randn(500), #set color equal to a variable</span></div><div class="line">        color=feature_dataframe[<span class="string">'Gradient Boost feature importances'</span>].values,</div><div class="line">        colorscale=<span class="string">'Portland'</span>,</div><div class="line">        showscale=<span class="keyword">True</span></div><div class="line">    ),</div><div class="line">    text=feature_dataframe[<span class="string">'features'</span>].values</div><div class="line">)</div><div class="line">data = [trace]</div><div class="line"></div><div class="line">layout = go.Layout(</div><div class="line">    autosize=<span class="keyword">True</span>,</div><div class="line">    title=<span class="string">'Gradient Boosting Feature Importance'</span>,</div><div class="line">    hovermode=<span class="string">'closest'</span>,</div><div class="line">    <span class="comment">#     xaxis= dict(</span></div><div class="line">    <span class="comment">#         title= 'Pop',</span></div><div class="line">    <span class="comment">#         ticklen= 5,</span></div><div class="line">    <span class="comment">#         zeroline= False,</span></div><div class="line">    <span class="comment">#         gridwidth= 2,</span></div><div class="line">    <span class="comment">#     ),</span></div><div class="line">    yaxis=dict(</div><div class="line">        title=<span class="string">'Feature Importance'</span>,</div><div class="line">        ticklen=<span class="number">5</span>,</div><div class="line">        gridwidth=<span class="number">2</span></div><div class="line">    ),</div><div class="line">    showlegend=<span class="keyword">False</span></div><div class="line">)</div><div class="line">fig = go.Figure(data=data, layout=layout)</div><div class="line">py.iplot(fig, filename=<span class="string">'scatter2010'</span>)</div></pre></td></tr></table></figure>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/日记/" rel="tag"># 日记</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/09/14/二战托福/" rel="next" title="二战托福">
                <i class="fa fa-chevron-left"></i> 二战托福
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
      <div id="disqus_thread">
        <noscript>
          Please enable JavaScript to view the
          <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a>
        </noscript>
      </div>
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel sidebar-panel-active">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          
            <p class="site-author-name" itemprop="name">SE</p>
            <p class="site-description motion-element" itemprop="description"></p>
        </div>

        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
            
              <a href="/archives/">
            
                <span class="site-state-item-count">53</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          

          
            
            
            <div class="site-state-item site-state-tags">
              
                <span class="site-state-item-count">6</span>
                <span class="site-state-item-name">标签</span>
              
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/Becomebright" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>GitHub</a>
              </span>
            
              <span class="links-of-author-item">
                <a href="15652587063@163.com" target="_blank" title="E-Mail">
                  
                    <i class="fa fa-fw fa-163"></i>E-Mail</a>
              </span>
            
          
        </div>

        
        

        
        

        


      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        
<div class="copyright" >
  
  &copy;  2017 &mdash; 
  <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">SE</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动</div>

  <span class="post-meta-divider">|</span>

  <div class="theme-info">主题 &mdash; <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.2</div>

        
<div class="busuanzi-count">
  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      
    </span>
  
</div>








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.2"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.2"></script>



  
  

  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.2"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.2"></script>


  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.2"></script>



  


  

    
      <script id="dsq-count-scr" src="https://Becomebright.disqus.com/count.js" async></script>
    

    
      <script type="text/javascript">
        var disqus_config = function () {
          this.page.url = 'http://yoursite.com/2018/10/13/Data-Sience——Kaggle-Titanic/';
          this.page.identifier = '2018/10/13/Data-Sience——Kaggle-Titanic/';
          this.page.title = 'Data Sience——Kaggle.Titanic';
        };
        var d = document, s = d.createElement('script');
        s.src = 'https://Becomebright.disqus.com/embed.js';
        s.setAttribute('data-timestamp', '' + +new Date());
        (d.head || d.body).appendChild(s);
      </script>
    

  




	





  










  





  

  

  

  
  


  

  

</body>
</html>
